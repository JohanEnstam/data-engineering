# ğŸš€ GCP Kostnadseffektiv Deployment Guide

## âœ… **Status: Kursprojekt-fokuserad GCP Pipeline**

**VÃ¥r situation:**
- ğŸ“ **Kursprojekt** - 4 veckor kvar, behÃ¶ver fungerande pipeline fÃ¶r betyg
- ğŸ’° **$300 free credits** - Vill inte brÃ¤nna i onÃ¶dan
- ğŸ¯ **100 spel** - Nuvarande dataset, vill expandera senare
- ğŸ“š **LÃ¤rande-fokus** - Vill fÃ¶rstÃ¥ varje steg, inte bygga production system

**Vad vi har implementerat:**
- âœ… **Secret Manager** - SÃ¤ker lagring av IGDB credentials
- âœ… **Cloud Run (Data Collection)** - Serverless IGDB data collection med Docker
- âœ… **BigQuery** - Data warehouse fÃ¶r spel data (automatisk integration)
- âœ… **Google Container Registry** - Docker image storage
- ğŸ”„ **Cloud Run (FastAPI + Next.js)** - Application hosting (nÃ¤sta steg)
- ğŸ”„ **Cloud Build CI/CD** - Automatisk deployment (nÃ¤sta steg)
- ğŸ”„ **Monitoring & Alerting** - Budget och performance alerts (nÃ¤sta steg)
- ğŸ”„ **Cloud Composer** - Planerat fÃ¶r senare (nÃ¤r vi har fungerande grund)

---

## ğŸ‰ **AKTUELLA FRAMSTEG (2025-01-15) - PIPELINE KOMPLETT!**

### **âœ… Vad vi har Ã¥stadkommit:**

**ğŸ” Secret Manager Setup:**
- âœ… Skapat `CLIENT_ID` och `CLIENT_SECRET` secrets
- âœ… Konfigurerat Cloud Run service account permissions
- âœ… SÃ¤ker credential hantering fÃ¶r IGDB API

**ğŸ³ Docker & Container Registry:**
- âœ… Byggt Docker image fÃ¶r IGDB data collection
- âœ… Pushat till Google Container Registry (`gcr.io/exalted-tempo-471613-e2/igdb-data-collector`)
- âœ… Konfigurerat Docker fÃ¶r GCR authentication

**â˜ï¸ Cloud Run Services (KOMPLETT PIPELINE):**
- âœ… **Data Collection:** `collect-igdb-data` service
  - Service URL: `https://collect-igdb-data-3sp2ul3fea-ew.a.run.app`
  - Testat med 20 spel - **FUNGERAR PERFEKT!**
- âœ… **Backend API:** `igdb-backend` service (BigQuery integration)
  - Service URL: `https://igdb-backend-3sp2ul3fea-ew.a.run.app`
  - Endpoints: `/games`, `/stats`, `/api/budget`, `/api/recommendations/*`
- âœ… **Frontend Dashboard:** `igdb-frontend` service
  - Service URL: `https://igdb-frontend-3sp2ul3fea-ew.a.run.app`
  - **FULLSTÃ„NDIGT FUNGERANDE DASHBOARD!** ğŸ‰

**ğŸ“Š BigQuery Integration:**
- âœ… Automatisk data upload till BigQuery
- âœ… Tabell: `exalted-tempo-471613-e2.igdb_game_data.games_raw`
- âœ… Data sparas som JSON med timestamp
- âœ… Backend lÃ¤ser direkt frÃ¥n BigQuery

**ğŸ”§ Problem-solving (ALLA LÃ–STA):**
- âœ… LÃ¶st IGDB release_dates komplexitet (hoppar Ã¶ver fÃ¶r nu)
- âœ… Fixat Python scope issues med helper functions
- âœ… Hanterat Secret Manager permissions
- âœ… Fixat Docker build errors (`COPY data/` problem)
- âœ… Fixat Pydantic validation fÃ¶r `release_year` som kan vara `None`
- âœ… Fixat Frontend TypeScript errors i `pipeline-canvas.tsx`
- âœ… Fixat Frontend-Backend connection (localhost â†’ Cloud Run URLs)
- âœ… Lade till saknade API endpoints fÃ¶r frontend kompatibilitet
- âœ… Fixat BigQuery response format och `DataQualityReport` struktur

### **ğŸ‰ PIPELINE STATUS: FULLSTÃ„NDIGT FUNGERANDE!**
- âœ… **End-to-End:** IGDB API â†’ Cloud Storage â†’ BigQuery â†’ FastAPI â†’ Next.js Dashboard
- âœ… **20 spel** visas korrekt i dashboard
- âœ… **Inga fel** i browser console
- âœ… **Alla endpoints** fungerar
- âœ… **Live data** frÃ¥n BigQuery till frontend

### **ğŸ“ˆ Senaste Test Resultat:**
```json
{
  "status": "success",
  "games_collected": 20,
  "file_saved": "raw_data/igdb_games_20250115_121608.json",
  "bigquery_table": "exalted-tempo-471613-e2.igdb_game_data.games_raw",
  "timestamp": "20250115_121608"
}
```

---

## ğŸ¯ **UPPDATERAD DEPLOYMENT ROADMAP**

### **Fas 1: Enkel Pipeline (1-2 dagar) - AKTUELL**

#### **1.1 Cloud Functions Setup (IGDB Data Collection)**

```bash
# Aktivera venv fÃ¶rst
source venv/bin/activate

# Aktivera nÃ¶dvÃ¤ndiga APIs
gcloud services enable cloudfunctions.googleapis.com
gcloud services enable bigquery.googleapis.com
gcloud services enable storage.googleapis.com
gcloud services enable secretmanager.googleapis.com

# Skapa secrets fÃ¶r IGDB credentials
echo "your-twitch-client-id" | gcloud secrets create igdb-client-id --data-file=-
echo "your-twitch-client-secret" | gcloud secrets create igdb-client-secret --data-file=-

# Deploy Cloud Function fÃ¶r data collection
cd gcp
zip -r igdb-data-collector.zip .
gcloud functions deploy igdb-data-collector \
  --runtime python39 \
  --trigger-http \
  --allow-unauthenticated \
  --memory 1024MB \
  --timeout 540s \
  --region europe-west1 \
  --source . \
  --entry-point collect_igdb_data \
  --set-secrets IGDB_CLIENT_ID=igdb-client-id:latest,IGDB_CLIENT_SECRET=igdb-client-secret:latest
```

#### **1.2 BigQuery Setup (Data Storage)**

```bash
# Skapa dataset fÃ¶r IGDB data
bq mk --dataset --location=EU exalted-tempo-471613-e2:igdb_game_data

# Skapa tabell fÃ¶r raw data
bq mk --table \
  --schema="id:INTEGER,name:STRING,summary:STRING,rating:FLOAT,release_year:INTEGER,genres:STRING,platforms:STRING,themes:STRING,game_modes:STRING,player_perspectives:STRING,collected_at:TIMESTAMP" \
  exalted-tempo-471613-e2:igdb_game_data.games_raw
```

#### **1.3 Cloud Run Setup (Application Hosting)**

```bash
# Bygg och push backend image
docker build -f Dockerfile -t gcr.io/exalted-tempo-471613-e2/igdb-backend:latest .
docker push gcr.io/exalted-tempo-471613-e2/igdb-backend:latest

# Deploy backend till Cloud Run
gcloud run deploy igdb-backend \
  --image gcr.io/exalted-tempo-471613-e2/igdb-backend:latest \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --port 8000 \
  --memory 1Gi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 10 \
  --set-env-vars="ENVIRONMENT=production,PROJECT_ID=exalted-tempo-471613-e2"

# Bygg och push frontend image
docker build -f frontend/Dockerfile -t gcr.io/exalted-tempo-471613-e2/igdb-frontend:latest ./frontend
docker push gcr.io/exalted-tempo-471613-e2/igdb-frontend:latest

# Deploy frontend till Cloud Run
BACKEND_URL=$(gcloud run services describe igdb-backend --region=europe-west1 --format='value(status.url)')
gcloud run deploy igdb-frontend \
  --image gcr.io/exalted-tempo-471613-e2/igdb-frontend:latest \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --port 3000 \
  --memory 512Mi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 5 \
  --set-env-vars="NEXT_PUBLIC_API_URL=$BACKEND_URL"
```

### **Fas 2: Expansion (1-2 dagar)**

#### **2.1 Skala till fler spel**

```bash
# Testa med 1000 spel
curl -X POST "https://europe-west1-exalted-tempo-471613-e2.cloudfunctions.net/igdb-data-collector" \
  -H "Content-Type: application/json" \
  -d '{"games_limit": 1000}'

# Ã–vervaka kostnader
gcloud billing budgets list
```

#### **2.2 FÃ¶rbÃ¤ttra ML-modellen**

```bash
# KÃ¶r lokal ML-trÃ¤ning med fler spel
source venv/bin/activate
python src/models/game_recommender.py --games-limit 1000

# Testa modellen
python src/models/game_recommender.py --test-model
```

### **Fas 3: Avancerat (valfritt)**

#### **3.1 Cloud Composer (NÃ¤r vi har fungerande grund)**

```bash
# Skapa Composer environment
gcloud composer environments create igdb-data-pipeline \
  --location=europe-west1-a \
  --python-version=3 \
  --node-count=3 \
  --machine-type=n1-standard-2 \
  --disk-size=100 \
  --environment-size=medium

# Ladda upp DAGs
COMPOSER_BUCKET=$(gcloud composer environments describe igdb-data-pipeline --location=europe-west1-a --format='value(config.dagGcsPrefix)' | sed 's|/dags||')
gsutil cp airflow/dags/*.py gs://$COMPOSER_BUCKET/dags/
```

#### **3.2 Vertex AI AutoML**

```bash
# KÃ¶r AutoML setup
python src/automl_setup.py

# Detta kommer:
# 1. Ladda data frÃ¥n BigQuery
# 2. FÃ¶rbereda fÃ¶r AutoML
# 3. Skapa dataset i Vertex AI
# 4. Starta trÃ¤ningsjobb
```

---

## ğŸ’° **KOSTNADJÃ„MFÃ–RELSE**

### **Alternativ 1: Enkel Pipeline (Rekommenderat)**

| **Service** | **Kostnad/MÃ¥nad** | **AnvÃ¤ndning** |
|-------------|-------------------|----------------|
| **Cloud Functions** | ~$5 | Per anrop |
| **BigQuery** | ~$10 | Per query |
| **Cloud Run** | ~$15 | Per request |
| **Cloud Storage** | ~$5 | Per GB |
| **Total** | **~$35/mÃ¥nad** | **Skalbar** |

### **Alternativ 2: Cloud Composer Pipeline**

| **Service** | **Kostnad/MÃ¥nad** | **AnvÃ¤ndning** |
|-------------|-------------------|----------------|
| **Cloud Composer** | ~$300 | 24/7 |
| **BigQuery** | ~$10 | Per query |
| **Cloud Run** | ~$15 | Per request |
| **Cloud Storage** | ~$5 | Per GB |
| **Total** | **~$330/mÃ¥nad** | **Fast kostnad** |

---

## ğŸ¯ **VARFÃ–R ALTERNATIV 1?**

### **FÃ¶rdelar:**
- âœ… **Kostnadseffektivt** - Sparar dina free credits
- âœ… **Snabbt att fÃ¥ igÃ¥ng** - Fungerande pipeline pÃ¥ nÃ¥gra timmar
- âœ… **LÃ¤rande-vÃ¤rde** - Du lÃ¤r dig Cloud Functions, BigQuery, Cloud Run
- âœ… **Skalbar** - Fungerar fÃ¶r 100 spel och 334,000 spel
- âœ… **Fokuserat** - NÃ¥ ditt mÃ¥l snabbt

### **Nackdelar:**
- âŒ **Mindre orchestration** - Ingen Airflow DAG
- âŒ **Manuell skalning** - MÃ¥ste hantera triggers sjÃ¤lv
- âŒ **Mindre professionell** - Inte som verkliga production systems

---

## ğŸš€ **IMPLEMENTATION STEG**

### **Steg 1: GrundlÃ¤ggande Setup**

```bash
# Aktivera venv fÃ¶rst
source venv/bin/activate

# Aktivera alla nÃ¶dvÃ¤ndiga APIs
gcloud services enable cloudfunctions.googleapis.com
gcloud services enable bigquery.googleapis.com
gcloud services enable storage.googleapis.com
gcloud services enable secretmanager.googleapis.com
gcloud services enable run.googleapis.com
gcloud services enable cloudbuild.googleapis.com
gcloud services enable monitoring.googleapis.com

# Verifiera att APIs Ã¤r aktiverade
gcloud services list --enabled --filter="name:(cloudfunctions OR bigquery OR storage OR secretmanager OR run OR cloudbuild OR monitoring)"
```

### **Steg 2: Data Collection**

```bash
# Skapa secrets fÃ¶r IGDB credentials
echo "your-twitch-client-id" | gcloud secrets create igdb-client-id --data-file=-
echo "your-twitch-client-secret" | gcloud secrets create igdb-client-secret --data-file=-

# Deploy Cloud Function
cd gcp
zip -r igdb-data-collector.zip .
gcloud functions deploy igdb-data-collector \
  --runtime python39 \
  --trigger-http \
  --allow-unauthenticated \
  --memory 1024MB \
  --timeout 540s \
  --region europe-west1 \
  --source . \
  --entry-point collect_igdb_data \
  --set-secrets IGDB_CLIENT_ID=igdb-client-id:latest,IGDB_CLIENT_SECRET=igdb-client-secret:latest
```

### **Steg 3: Data Storage**

```bash
# Skapa BigQuery dataset
bq mk --dataset --location=EU exalted-tempo-471613-e2:igdb_game_data

# Skapa tabell fÃ¶r raw data
bq mk --table \
  --schema="id:INTEGER,name:STRING,summary:STRING,rating:FLOAT,release_year:INTEGER,genres:STRING,platforms:STRING,themes:STRING,game_modes:STRING,player_perspectives:STRING,collected_at:TIMESTAMP" \
  exalted-tempo-471613-e2:igdb_game_data.games_raw
```

### **Steg 4: Application Deployment**

```bash
# Deploy backend
docker build -f Dockerfile -t gcr.io/exalted-tempo-471613-e2/igdb-backend:latest .
docker push gcr.io/exalted-tempo-471613-e2/igdb-backend:latest

gcloud run deploy igdb-backend \
  --image gcr.io/exalted-tempo-471613-e2/igdb-backend:latest \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --port 8000 \
  --memory 1Gi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 10

# Deploy frontend
docker build -f frontend/Dockerfile -t gcr.io/exalted-tempo-471613-e2/igdb-frontend:latest ./frontend
docker push gcr.io/exalted-tempo-471613-e2/igdb-frontend:latest

BACKEND_URL=$(gcloud run services describe igdb-backend --region=europe-west1 --format='value(status.url)')
gcloud run deploy igdb-frontend \
  --image gcr.io/exalted-tempo-471613-e2/igdb-frontend:latest \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --port 3000 \
  --memory 512Mi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 5 \
  --set-env-vars="NEXT_PUBLIC_API_URL=$BACKEND_URL"
```

---

## ğŸ“Š **MONITORING OCH KOSTNADSHANTERING**

### **Budget Alerts**

```bash
# Skapa budget alert
gcloud billing budgets create \
  --billing-account=$(gcloud billing accounts list --format='value(name)' | head -1) \
  --display-name="IGDB Pipeline Budget Alert" \
  --budget-amount=100USD \
  --threshold-rule=percent=80 \
  --threshold-rule=percent=100 \
  --notification-rule=email=johanenstam@gmail.com
```

### **KostnadsÃ¶vervakning**

```bash
# Kontrollera dagliga kostnader
gcloud billing budgets list

# Kontrollera service-specifika kostnader
gcloud logging read "resource.type=cloud_function" --limit=10
gcloud logging read "resource.type=cloud_run_revision" --limit=10
```

---

## ğŸ“ **LÃ„RANDE-MÃ…L**

### **Vad du kommer lÃ¤ra dig:**

1. **Cloud Functions** - Serverless computing
2. **BigQuery** - Data warehouse och SQL
3. **Cloud Run** - Container hosting
4. **Secret Manager** - SÃ¤ker credential hantering
5. **Cloud Build** - CI/CD pipelines
6. **Monitoring** - Kostnad och performance tracking

### **NÃ¤sta steg - SERVERLESS ML PIPELINE:**

1. **ML Training Function** - Automatisk model training (Cloud Functions)
2. **Model Serving Function** - Live rekommendationer (Cloud Functions)
3. **Cloud Scheduler** - Automatisk orchestration (Serverless)
4. **Backend Integration** - ML model i FastAPI
5. **Frontend Recommendations** - Rekommendationsfunktionalitet
6. **Skala till fler spel** - 1000+ spel frÃ¥n IGDB

**ğŸ“‹ Detaljerad plan:** Se `docs/SERVERLESS_ML_PIPELINE.md`

**ğŸ’° Kostnad:** ~$15-30/mÃ¥nad (vs $300-400/mÃ¥nad fÃ¶r Cloud Composer)

---

## ğŸš¨ **TROUBLESHOOTING**

### **Vanliga problem:**

**"Cloud Function timeout"**
```bash
# Ã–ka timeout
gcloud functions deploy igdb-data-collector --timeout 900s
```

**"BigQuery permission denied"**
```bash
# Kontrollera service account permissions
gcloud projects get-iam-policy exalted-tempo-471613-e2
```

**"Cloud Run deployment failed"**
```bash
# Kontrollera Docker build
docker build -f Dockerfile -t test-backend .
docker run -p 8000:8000 test-backend
```

---

## ğŸ‰ **NÃ„STA STEG**

### **Omedelbart (idag):**
1. âœ… Aktivera alla nÃ¶dvÃ¤ndiga APIs
2. âœ… Skapa secrets fÃ¶r IGDB credentials
3. âœ… Deploya Cloud Run service fÃ¶r data collection
4. âœ… Testa IGDB data collection (5 spel samlade!)

### **Denna vecka:**
1. ğŸ”„ SÃ¤tt upp BigQuery dataset
2. ğŸ”„ Deploya Cloud Run services
3. ğŸ”„ Testa hela pipeline med 100 spel

### **NÃ¤sta vecka:**
1. ğŸš€ Skala till fler spel (1000+)
2. ğŸš€ FÃ¶rbÃ¤ttra ML-modellen
3. ğŸš€ LÃ¤gg till Cloud Composer (valfritt)

---

**ğŸ¯ NÃ¤r du har fÃ¶ljt denna guide kommer du att ha en kostnadseffektiv, skalbar GCP pipeline som fungerar fÃ¶r ditt kursprojekt och kan expanderas nÃ¤r du Ã¤r redo!**
